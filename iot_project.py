# -*- coding: utf-8 -*-
"""IoT_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FR2a2gcOQlDHYxnU1xqJks4d7nQmE0R2

# **Details** :-
*The data (iot_telemetry_data.csv) was generated from 3 identical, custom-built sensor arrays, each connected to a Raspberry Pi device. These IoT devices were placed in different physical locations with varied environmental conditions.*

*Each IoT device collected 7 readings/features from 4 sensors at regular intervals. The readings include temperature (temp), humidity, carbon monoxide (CO), liquid petroleum gas (LPG), smoke, light, and motion. The data spans from 07/12/2020 00:00:00 UTC to 07/19/2020 23:59:59 UTC, with a total of 405,184 rows of data.*

*The sensor readings, along with a unique device ID and timestamp, were published as a single message, using the ISO standard Message Queuing Telemetry Transport (MQTT) network protocol.*


# **Project Idea** :-

*1) Conduct time-series analysis on the three IoT devices to identify the most effective device.*

**Solution :-** *Shown in Bivariate Analysis*

*2) Identify which Feature correlates more*

**Solution :-** *Shown in Correlation*

*3) Utilize the collected readings, comprising multiple (7) features, to determine the likelihood of detecting a fire through the presence of light.*

**Solution :-** *Shown in Classification*

# Importing all necessary libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""# Loading the dataset"""

# The parse function automatically infers the data types and column names based on the input data. It also handles missing values and duplicate rows.
def parse(x):
    return pd.to_datetime(x, infer_datetime_format=True, unit='s',utc=True)

nrows_read = 100000 # specify 'None' if want to read whole file (405,184 rows)

df = pd.read_csv("iot_telemetry_data.csv",
                  delimiter=',',
                  nrows = nrows_read,
                  header=0,
                  infer_datetime_format=True,
                  date_parser=parse,
                  index_col=['ts'])

"""# Exploratory Data Analysis (EDA)"""

# sort data by the increasing value of ts
df = df.sort_values(by='ts', ascending=True)

# convert celsius to fahrenheit (Â°C to Â°F), because some industries or regions might have specific standards or regulations that require temperature data to be reported in a particular unit, and in such cases, conversion becomes necessary.
df['temp'] = (df['temp'] * 1.8) + 32

# preview data
df.head()

# check numbers of unique value each column

df.nunique()

df.isnull().sum()
# No null character is present in the dataset

df.info()

# Transforming boolean columns 'light' and 'motion' into integers
df['light'] = df['light'].astype(int)
df['motion'] = df['motion'].astype(int)

df.info()

# 3 IoT devices that we're using
df['device'].value_counts()

# 'light' column contains False and True values
df['light'].value_counts()

# 'motion' column also contains False and True values
df['motion'].value_counts()

df[df.duplicated].value_counts()
# The three device names mentioned below were repeated multiple times.
# After removing duplicates, the accuracy of classification decreases. Therefore, we need to retain the duplicate values.

# group data by iot device
grouped_data = df.groupby('device')
max_min_data = grouped_data[['temp', 'humidity', 'lpg', 'smoke', 'co']].agg(['max', 'min'])
print(max_min_data.head())

print('DataFrame Stats')
print('-------------')
print('Record count: {:,}'.format(df['temp'].count()))
print('-------------')
print('Time range (min): {:%Y-%m-%d %H:%M:%S %Z}'.format(df.index[1]))
print('Time range (max): {:%Y-%m-%d %H:%M:%S %Z}'.format(df.index[-1]))
print('Temperature (min): {:.2f}'.format(df['temp'].min()))
print('Temperature (max): {:.2f}'.format(df['temp'].max()))
print('Humidity (min): {:.2f}{}'.format(df['humidity'].min(), '%'))
print('Humidity (max): {:.2f}{}'.format(df['humidity'].max(), '%'))
print('-------------')
print('Record count:\n{}'.format(grouped_data.size()))

# Display basic summary statistics
summary_stats = df.describe()
print(summary_stats)

"""# Data Cleaning"""

# filter temp/humidity, by device, for outliers (>1% & <99%)
df = df.loc[df['temp'] >df.groupby('device').temp.transform(lambda x: x.quantile(.01))]
df = df.loc[df['temp'] < df.groupby('device').temp.transform(lambda x: x.quantile(.99))]

df = df.loc[df['humidity'] > df.groupby('device').humidity.transform(lambda x: x.quantile(.01))]
df = df.loc[df['humidity'] < df.groupby('device').humidity.transform(lambda x: x.quantile(.99))]

"""# Visualization

## Plot to check for outliers
"""

# Create subplots for each numerical column
fig, axes = plt.subplots(2, 3, figsize=(15, 5))

# Plot boxplots for each column
sns.boxplot(x=df['temp'], ax=axes[0, 0])
sns.boxplot(x=df['humidity'], ax=axes[0, 1])
sns.boxplot(x=df['lpg'], ax=axes[0, 2])
sns.boxplot(x=df['smoke'], ax=axes[1, 0])
sns.boxplot(x=df['co'], ax=axes[1, 1])

# Adjust spacing and show plot
plt.tight_layout()
plt.show()

"""## Univariate Analysis"""

# Histogram for a numerical variable
plt.hist(df['device'], bins=10, color='blue', edgecolor='black')
plt.title('Histogram of Numerical Column')
plt.xlabel('Value')
plt.ylabel('Frequency')
plt.show()

"""## Bivariate Analysis"""

# group the data by device and bar-plot the graph

# Group the data by device and plot the graph
grouped_data = df.groupby('device')[['temp', 'humidity']].mean()

# Plot the data
grouped_data.plot(kind='bar', figsize=(10, 5))

# Add title and labels
plt.title('Average Sensor Readings by Device')
plt.xlabel('Device')
plt.ylabel('Average Reading')

# Rotate x-axis labels for readability
plt.xticks(rotation=45)

# Show the plot
plt.show()

# Group the data by device
grouped_data = df.groupby('device')
f, axes = plt.subplots(1,3, figsize=(20, 6))
# Plot boxplots for each numerical column
for i, column in enumerate(['lpg', 'smoke', 'co']):
    sns.boxplot(x='device', y=column, data=df, palette='Set2',hue='device', ax=axes[i])
    axes[i].set_title(f' {column} ')

# Temperature vs Humidity
_, ax = plt.subplots(1, 1, figsize=(18, 9))
for device, group in grouped_data:
    ax.plot(group.temp,
            group.humidity,
            marker='o',
            linestyle='',
            alpha=.5,
            ms=10,
            label=device)
ax.grid()
ax.margins(0.05)
ax.legend()
plt.title('Temperature vs. Humidity')
plt.xlabel('Temperature (ËšF)')
plt.ylabel('Humidity (%)')
plt.show()

# Temperature Graph (Moving Average) : Temperature vs. Time
fig, ax = plt.subplots(1, 1, figsize=(18, 9))
for device, group in grouped_data:
    group.mean = group.temp.rolling(window=20).mean()
    ax.plot(group.mean,
            label=device)
fig.autofmt_xdate()
ax.grid()
ax.margins(0.05)
ax.legend()
plt.title('Temperature Comparison over Time')
plt.ylabel('Temperature (ËšF)')
plt.xlabel('Time')
plt.show()

'''
Conclusion wrt temperature:-

1) Devices b8:27:eb:bf:9d:51 and 00:0f:00:70:91:0a showing More Ups and Downs (Less Stable):
Advantages: Provides more detailed information about short-term variations and potential patterns.
Considerations: May be more susceptible to noise, outliers, or short-term shocks.

2) Device 1c:bf:ce:15:ec:4d contains Less Ups and Downs (More Stable):
Advantages: Tends to reveal longer-term trends and may be less influenced by short-term fluctuations.
Considerations: Might smooth out important short-term variations, making it less responsive to rapid changes.

'''

# Humidity Graph (Moving Average) : Humidity vs. Time
fig, ax = plt.subplots(1, 1, figsize=(18, 9))
for device, group in grouped_data:
    group.mean = group.humidity.rolling(window=20).mean()
    ax.plot(group.mean,
            label=device)
fig.autofmt_xdate()
ax.grid()
ax.margins(0.05)
ax.legend()
plt.title('Humidity Comparison over Time')
plt.ylabel('Humidity (%)')
plt.xlabel('Time')
plt.show()

'''
Conclusion wrt humidity (same as temperature):-

1) Devices b8:27:eb:bf:9d:51 and 00:0f:00:70:91:0a showing More Ups and Downs (Less Stable):
Advantages: Provides more detailed information about short-term variations and potential patterns.
Considerations: May be more susceptible to noise, outliers, or short-term shocks.

2) Device 1c:bf:ce:15:ec:4d contains Less Ups and Downs (More Stable):
Advantages: Tends to reveal longer-term trends and may be less influenced by short-term fluctuations.
Considerations: Might smooth out important short-term variations, making it less responsive to rapid changes.

'''

"""# Applying ML concepts

## Correlation
"""

# Drop the sensor column because Correlation can be seen only in Quantitative data!
corr_data = df.drop(['device'],axis=1)

# Compute the correlation matrix
corr_matrix = corr_data.corr()

# Create a heatmap to visualize the correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix for all sensors')
plt.show()

# Set the diagonal values (self-correlation) to NaN
np.fill_diagonal(corr_matrix.values, np.nan)

# Find the maximum correlation value
max_corr_value = corr_matrix.max().max()

# Find the indices (i, j) of the maximum correlation value
max_corr_indices = np.where(corr_matrix.values == max_corr_value)

# Get the names of the features corresponding to the maximum correlation
feature1 = corr_matrix.columns[max_corr_indices[1][0]]
feature2 = corr_matrix.columns[max_corr_indices[0][0]]

print(f"The maximum correlation value (excluding 1) is {max_corr_value:.2f}")
print(f"It occurs between features '{feature1}' and '{feature2}'. So, they are highly correlated.", '\n', "Therefore, The classification will be highly depends on the value of smoke and lpg")

"""## Classification"""

corr_data['light']

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# X contains all features excluding the "light" column
X = corr_data.drop("light", axis=1)
# y contains the "light" column
y = corr_data["light"]

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Create a RandomForestClassifier (you can choose a different classifier based on your requirements)
classifier = RandomForestClassifier(n_estimators=200, random_state=42)

# Train the classifier
classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = classifier.predict(X_test)

# Evaluate the classifier
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print(f"Confusion Matrix:\n{conf_matrix}")
print(f"Classification Report:\n{classification_rep}")

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)

# Define class labels
classes = ['Class 0', 'Class 1']

# Plot Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

X_test

row_index = 0  # Replace with the actual integer index of the row you want
sample_row = X_test.iloc[[row_index]]
predicted_value = classifier.predict(sample_row)

# Display the results
print(sample_row, '\n')
print("Predicted value:", predicted_value, '\n')
print("Original values in y_test:", y_test.iloc[row_index], '\n')

'''
Conclusion :-

For the values of [co, humidity, lpg, motion, smoke, temp]
= [0.005132, 51.6, 0.007846, 0, 0.020969, 71.24], our model is predicting the value of light = 0, indicating the False class.
This denotes that the environmental conditions are not indicative of a fire hazard. âŒðŸ”¥
'''

# find places where values of y_test = 1
ytest_1 = [i for i, x in enumerate(y_test) if x == 1]
print(len(ytest_1))

row_index = 8
sample_row = X_test.iloc[[row_index]]
predicted_value = classifier.predict(sample_row)

# Display the results
print(sample_row, '\n')
print("Predicted value:", predicted_value, '\n')
print("Original values in y_test:", y_test.iloc[row_index], '\n')

'''
Conclusion :-

For the values of [co, humidity, lpg, motion, smoke, temp]
= [0.00385, 73.199997, 0.006373, 0, 0.016791, 75.919999], our model is predicting the value of light = 1, indicating the True class.
This denotes that the environmental condition may lead to a fire. âœ”ï¸ðŸ”¥
'''

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc


# Plot ROC Curve
y_prob = classifier.predict_proba(X_test)[:, 1]  # Probability of belonging to class 1
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

'''
Conclusion :-

1) Diagonal line (from (0,0) to (1,1)): Represents a random classifier. A model that makes random guesses would follow this diagonal line.
2) Top-left corner (0,1): Ideal point. It represents a perfect classification where the model has 100% true positives and 0% false positives. This is the point we want your model to be close to.
3) Bottom-right corner (1,0): Worst point. It represents a model that predicts all negatives as positives (100% false positives) and misses all positives (0% true positives).
4) AUC (Area Under the Curve): The overall performance of a classifier is often summarized using the area under the ROC curve (AUC). A higher AUC indicates better model performance, i.e. AUC = 1 means 100%
5) Slope of the ROC curve: The steepness of the ROC curve indicates how well the model is separating classes. Steeper curves generally indicate better performance.

In our case all points were satisfied except the 3rd one, means our model is highly accurate.
'''